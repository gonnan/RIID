{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-12T01:08:11.944207Z",
     "iopub.status.busy": "2021-01-12T01:08:11.943475Z",
     "iopub.status.idle": "2021-01-12T01:08:14.348996Z",
     "shell.execute_reply": "2021-01-12T01:08:14.348043Z"
    },
    "papermill": {
     "duration": 2.426966,
     "end_time": "2021-01-12T01:08:14.349122",
     "exception": false,
     "start_time": "2021-01-12T01:08:11.922156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013464,
     "end_time": "2021-01-12T01:08:14.374944",
     "exception": false,
     "start_time": "2021-01-12T01:08:14.361480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Introduction and Credit\n",
    "\n",
    "I had a lot of fun with this competition, and I'm disappointed it's over because I was making really good progress towards the end. My final submission got up to 0.798, but it finished scoring after the competition had ended. I'm sure I could have gotten this well above 0.8 if I had the time. There are still a number of ideas I didn't get the chance to implement. \n",
    "\n",
    "The following kernels and github were instrumental in building this model.\n",
    "\n",
    "https://www.kaggle.com/wangsg/a-self-attentive-model-for-knowledge-tracing\n",
    "\n",
    "https://www.kaggle.com/mpware/sakt-fork\n",
    "\n",
    "https://github.com/arshadshk/SAINT-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011686,
     "end_time": "2021-01-12T01:08:14.399007",
     "exception": false,
     "start_time": "2021-01-12T01:08:14.387321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011977,
     "end_time": "2021-01-12T01:08:14.422817",
     "exception": false,
     "start_time": "2021-01-12T01:08:14.410840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The poorly named train-df-saint-not-binned contains a pre processed feather version of train_df. In that kernel, I calculate all the interesting features, then create artificial users for any user with more than seq_len interactions. So if a user had 160 interactions, I split this into two users: One with the final 100 interactions, and one with the first 60 interactions. This strategy seemed to work well when applied to my SAKT fork, so I kept it with my SAINT model. As a result of this, instead of 39000 users, the model trains on 120000 \"users\" or so. \n",
    "\n",
    "Given more time, I would have liked to experiment with other ways of creating sequences for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:08:14.453540Z",
     "iopub.status.busy": "2021-01-12T01:08:14.452544Z",
     "iopub.status.idle": "2021-01-12T01:08:35.845818Z",
     "shell.execute_reply": "2021-01-12T01:08:35.847115Z"
    },
    "papermill": {
     "duration": 21.412977,
     "end_time": "2021-01-12T01:08:35.847411",
     "exception": false,
     "start_time": "2021-01-12T01:08:14.434434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99271300 entries, 0 to 99271299\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Dtype\n",
      "---  ------                       -----\n",
      " 0   timestamp                    int64\n",
      " 1   user_id                      int64\n",
      " 2   content_id                   int16\n",
      " 3   answered_correctly           int8 \n",
      " 4   prior_question_elapsed_time  int16\n",
      " 5   part                         int8 \n",
      " 6   lag1                         int16\n",
      " 7   lag2                         int16\n",
      " 8   lag3                         int16\n",
      "dtypes: int16(5), int64(2), int8(2)\n",
      "memory usage: 2.6 GB\n",
      "CPU times: user 2.24 s, sys: 3.16 s, total: 5.4 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df = pd.read_feather('../input/train-df-saint-not-binned-everything/train_not_binned')\n",
    "train_df['prior_question_elapsed_time'].fillna(0, inplace=True)\n",
    "train_df['prior_question_elapsed_time'] /= 1000\n",
    "train_df['prior_question_elapsed_time'] = train_df['prior_question_elapsed_time'].round()\n",
    "train_df['prior_question_elapsed_time'] = train_df['prior_question_elapsed_time'].astype('int16')\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012327,
     "end_time": "2021-01-12T01:08:35.873713",
     "exception": false,
     "start_time": "2021-01-12T01:08:35.861386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:08:35.906704Z",
     "iopub.status.busy": "2021-01-12T01:08:35.905538Z",
     "iopub.status.idle": "2021-01-12T01:08:39.001006Z",
     "shell.execute_reply": "2021-01-12T01:08:39.000394Z"
    },
    "papermill": {
     "duration": 3.114918,
     "end_time": "2021-01-12T01:08:39.001134",
     "exception": false,
     "start_time": "2021-01-12T01:08:35.886216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'answered_correctly'\n",
    "MAX_SEQ = 100\n",
    "# content_ids = train_df[\"content_id\"].unique()\n",
    "NUM_QUESTIONS = len(train_df[\"content_id\"].unique()) + 1\n",
    "NUM_USERS = len(train_df['user_id'].unique())\n",
    "NUM_LAG1S = train_df['lag1'].max() + 1\n",
    "NUM_LAG2S = train_df['lag2'].max() + 1\n",
    "NUM_LAG3S = train_df['lag3'].max() + 1\n",
    "ELAPSED_TIMES = train_df['prior_question_elapsed_time'].max() + 1\n",
    "MODEL_BEST = 'model_best.pt'\n",
    "BS = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:08:39.035312Z",
     "iopub.status.busy": "2021-01-12T01:08:39.033879Z",
     "iopub.status.idle": "2021-01-12T01:14:01.172952Z",
     "shell.execute_reply": "2021-01-12T01:14:01.172376Z"
    },
    "papermill": {
     "duration": 322.158973,
     "end_time": "2021-01-12T01:14:01.173071",
     "exception": false,
     "start_time": "2021-01-12T01:08:39.014098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 9s, sys: 7.19 s, total: 5min 16s\n",
      "Wall time: 5min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Creates a Series with user_ids as indices and a tuple of all the content_ids and answered_correctlys as lists\n",
    "def create_group(df):\n",
    "    return df[['user_id', 'content_id', 'answered_correctly', 'lag1', 'lag2', 'lag3', 'part', 'prior_question_elapsed_time']].groupby('user_id').apply(lambda r: [\n",
    "        r['content_id'].values,\n",
    "        r['answered_correctly'].values,\n",
    "        r['lag1'].values,\n",
    "        r['lag2'].values,\n",
    "        r['lag3'].values,\n",
    "        r['part'].values,\n",
    "        r['prior_question_elapsed_time'].values])\n",
    "\n",
    "train_group = create_group(train_df)\n",
    "\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:01.209048Z",
     "iopub.status.busy": "2021-01-12T01:14:01.208214Z",
     "iopub.status.idle": "2021-01-12T01:14:01.533362Z",
     "shell.execute_reply": "2021-01-12T01:14:01.533856Z"
    },
    "papermill": {
     "duration": 0.347529,
     "end_time": "2021-01-12T01:14:01.533993",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.186464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1194644,), (36948,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_group = train_group.sample(frac=0.03)\n",
    "train_group = train_group.drop(valid_group.index).reset_index(drop=True)\n",
    "valid_group.reset_index(drop=True, inplace=True)\n",
    "train_group.shape, valid_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:01.583325Z",
     "iopub.status.busy": "2021-01-12T01:14:01.581832Z",
     "iopub.status.idle": "2021-01-12T01:14:01.584513Z",
     "shell.execute_reply": "2021-01-12T01:14:01.584997Z"
    },
    "papermill": {
     "duration": 0.037411,
     "end_time": "2021-01-12T01:14:01.585116",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.547705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAINTDataset(Dataset):\n",
    "    def __init__(self, user_sequences, num_questions, subset='train', max_seq=100, min_seq=10):\n",
    "        super(SAINTDataset, self).__init__()\n",
    "        self.max_seq = max_seq\n",
    "        self.num_questions = num_questions\n",
    "        self.user_sequences = user_sequences\n",
    "        self.subset = subset\n",
    "\n",
    "        self.user_ids = []\n",
    "        for user_id in user_sequences.index:\n",
    "            q, _, _, _, _, _, _ = user_sequences[user_id]\n",
    "            if len(q) < min_seq:\n",
    "                continue\n",
    "            self.user_ids.append(user_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        # question_id, answered_correctly, lag1, lag2, lag3, part, elapsed_time\n",
    "        q_, qa_, l1_, l2_, l3_, p_, el_ = self.user_sequences[user_id]\n",
    "        seq_len = len(q_)\n",
    "\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        l1 = np.zeros(self.max_seq, dtype=int)\n",
    "        l2 = np.zeros(self.max_seq, dtype=int)\n",
    "        l3 = np.zeros(self.max_seq, dtype=int)\n",
    "        p = np.zeros(self.max_seq, dtype=int)\n",
    "        el = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "#         # If there are more questions answered than max_seq, take the last max_seq sequences\n",
    "        if seq_len >= self.max_seq:\n",
    "            q[:] = q_[-self.max_seq:]\n",
    "            qa[:] = qa_[-self.max_seq:]\n",
    "            l1[:] = l1_[-self.max_seq:]\n",
    "            l2[:] = l2_[-self.max_seq:]\n",
    "            l3[:] = l3_[-self.max_seq:]\n",
    "            p[:] = p_[-self.max_seq:]\n",
    "            el[:] = el_[-self.max_seq:]\n",
    "        # If not, map our user_sequences to the tail end of q and qa, the start will be padded with zeros\n",
    "        else:\n",
    "            q[-seq_len:] = q_\n",
    "            qa[-seq_len:] = qa_\n",
    "            l1[-seq_len:] = l1_\n",
    "            l2[-seq_len:] = l2_\n",
    "            l3[-seq_len:] = l3_\n",
    "            el[-seq_len:] = el_\n",
    "        \n",
    "        r = np.zeros(self.max_seq, dtype=int)\n",
    "        r[1:] = qa[:-1].copy()\n",
    "        \n",
    "        return q, r, qa, l1, l2, l3, p, el "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014366,
     "end_time": "2021-01-12T01:14:01.614802",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.600436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:01.682556Z",
     "iopub.status.busy": "2021-01-12T01:14:01.656644Z",
     "iopub.status.idle": "2021-01-12T01:14:01.693383Z",
     "shell.execute_reply": "2021-01-12T01:14:01.693868Z"
    },
    "papermill": {
     "duration": 0.065052,
     "end_time": "2021-01-12T01:14:01.694005",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.628953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, dim=128):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(dim, dim)\n",
    "        self.layer2 = nn.Linear(dim, dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer2(   self.relu(   self.layer1(x)))\n",
    "\n",
    "    \n",
    "def future_mask(seq_length):\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_in, seq_len=100, embed_dim=128, nheads=4):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.part_embed = nn.Embedding(10, embed_dim)\n",
    "        \n",
    "        self.e_embed = nn.Embedding(n_in, embed_dim)\n",
    "        self.e_pos_embed = nn.Embedding(seq_len, embed_dim)\n",
    "        self.e_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.e_multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=nheads, dropout=0.2)\n",
    "        self.m_norm = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = FFN(embed_dim)\n",
    "    \n",
    "    def forward(self, e, p, first_block=True):\n",
    "        \n",
    "        if first_block:\n",
    "            e = self.e_embed(e)\n",
    "            p = self.part_embed(p)\n",
    "            e = e + p\n",
    "         \n",
    "        pos = torch.arange(self.seq_len).unsqueeze(0).to(device)\n",
    "        e_pos = self.e_pos_embed(pos)\n",
    "        e = e + e_pos\n",
    "        e = self.e_norm(e)\n",
    "        e = e.permute(1,0,2) #[bs, s_len, embed] => [s_len, bs, embed]     \n",
    "        n = e.shape[0]\n",
    "        \n",
    "        att_mask = future_mask(n).to(device)\n",
    "        att_out, _ = self.e_multi_att(e, e, e, attn_mask=att_mask)\n",
    "        m = e + att_out\n",
    "        m = m.permute(1,0,2)\n",
    "        \n",
    "        o = m + self.ffn(self.m_norm(m))\n",
    "        \n",
    "        return o\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_in, seq_len=100, embed_dim=128, nheads=4):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.r_embed = nn.Embedding(n_in, embed_dim)\n",
    "        self.r_pos_embed = nn.Embedding(seq_len, embed_dim)\n",
    "        self.r_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.l1_embed = nn.Embedding(NUM_LAG1S, embed_dim)\n",
    "        self.l2_embed = nn.Embedding(NUM_LAG2S, embed_dim)\n",
    "        self.l3_embed = nn.Embedding(NUM_LAG3S, embed_dim)\n",
    "        self.el_t_embed = nn.Embedding(ELAPSED_TIMES, embed_dim)\n",
    "        \n",
    "        self.r_multi_att1 = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=4, dropout=0.2)\n",
    "        self.r_multi_att2 = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=4, dropout=0.2)\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        \n",
    "        self.r_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.r_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.r_norm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    \n",
    "    def forward(self, r, o, l1, l2, l3, el, first_block=True):\n",
    "        \n",
    "        if first_block:\n",
    "            r = self.r_embed(r)\n",
    "            l1 = self.l1_embed(l1)\n",
    "            l2 = self.l2_embed(l2)\n",
    "            l3 = self.l3_embed(l3)\n",
    "            el = self.el_t_embed(el)\n",
    "\n",
    "            r = r + l1 + l2 + l3 + el\n",
    "  \n",
    "        pos = torch.arange(self.seq_len).unsqueeze(0).to(device)\n",
    "        r_pos_embed = self.r_pos_embed(pos)\n",
    "        r = r + r_pos_embed\n",
    "        r = self.r_norm1(r) \n",
    "        r = r.permute(1,0,2)   \n",
    "        n = r.shape[0]\n",
    "   \n",
    "        att_out1, _ = self.r_multi_att1(r, r, r, attn_mask=future_mask(n).to(device))\n",
    "        m1 = r + att_out1\n",
    "\n",
    "        o = o.permute(1,0,2)\n",
    "        o = self.r_norm2(o)\n",
    "        att_out2, _ = self.r_multi_att2(m1, o, o, attn_mask=future_mask(n).to(device))\n",
    "        \n",
    "        m2 = att_out2 + m1\n",
    "        m2 = m2.permute(1,0,2)        \n",
    "        m2 = self.r_norm3(m2)\n",
    "        \n",
    "        l = m2 + self.ffn(m2)\n",
    "        \n",
    "        return l\n",
    "\n",
    "# This is an altered version from https://github.com/arshadshk/SAINT-pytorch\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class SAINT(nn.Module):\n",
    "    def __init__(self, dim_model, num_en, num_de, heads_en, total_ex, total_in, heads_de, seq_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_en = num_en\n",
    "        self.num_de = num_de\n",
    "\n",
    "        self.encoder = get_clones( Encoder(n_in=total_ex, seq_len=seq_len, embed_dim=dim_model, nheads=heads_en) , num_en)\n",
    "        self.decoder = get_clones( Decoder(n_in=total_in, seq_len=seq_len, embed_dim=dim_model, nheads=heads_de) , num_de)\n",
    "\n",
    "        self.out = nn.Linear(in_features= dim_model , out_features=1)\n",
    "    \n",
    "    def forward(self, in_ex, in_in, l1, l2, l3, p, el):\n",
    "        \n",
    "        ## pass through each of the encoder blocks in sequence\n",
    "        first_block = True\n",
    "        for x in range(self.num_en):\n",
    "            if x>=1:\n",
    "                first_block = False\n",
    "            in_ex = self.encoder[x](in_ex, p, first_block=first_block)\n",
    "        \n",
    "        ## pass through each decoder blocks in sequence\n",
    "        first_block = True\n",
    "        for x in range(self.num_de):\n",
    "            if x>=1:\n",
    "                first_block = False\n",
    "            in_in = self.decoder[x]( in_in , in_ex, l1, l2, l3, el, first_block=first_block )\n",
    "\n",
    "        ## Output layer\n",
    "        in_in = torch.sigmoid( self.out( in_in ) )\n",
    "        return in_in.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:01.740241Z",
     "iopub.status.busy": "2021-01-12T01:14:01.739315Z",
     "iopub.status.idle": "2021-01-12T01:14:01.741332Z",
     "shell.execute_reply": "2021-01-12T01:14:01.741820Z"
    },
    "papermill": {
     "duration": 0.033399,
     "end_time": "2021-01-12T01:14:01.741941",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.708542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_iterator is our dataloader, criterion is nn.BCEWithLogitsLoss\n",
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        e = item[0].to(device).long()\n",
    "        r = item[1].to(device).long()\n",
    "        label = item[2].to(device).float()\n",
    "        l1 = item[3].to(device).long()\n",
    "        l2 = item[4].to(device).long()\n",
    "        l3 = item[5].to(device).long()\n",
    "        p = item[6].to(device).long()\n",
    "        el = item[7].to(device).long()\n",
    "\n",
    "        # Zero the gradients in the optimizer\n",
    "        optim.zero_grad()\n",
    "        # The results of one forward pass\n",
    "        output = model(e, r, l1, l2, l3, p, el)\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, torch.sigmoid(label))\n",
    "        # Calculate the gradients with respect to the loss\n",
    "        loss.backward()\n",
    "        # Adjust the parameters to minimize the loss based on these gradients\n",
    "        optim.step()\n",
    "        # Add our loss to the list of losses\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        output = output[:, -1]\n",
    "        label = label[:, -1] \n",
    "        pred = (output >= 0.5).long()\n",
    "         \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.mean(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:01.785832Z",
     "iopub.status.busy": "2021-01-12T01:14:01.782813Z",
     "iopub.status.idle": "2021-01-12T01:14:01.788169Z",
     "shell.execute_reply": "2021-01-12T01:14:01.788780Z"
    },
    "papermill": {
     "duration": 0.032934,
     "end_time": "2021-01-12T01:14:01.788907",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.755973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mpware/sakt-fork\n",
    "def valid_epoch(model, valid_iterator, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    #tbar = tqdm(valid_iterator)\n",
    "    for item in valid_iterator: # tbar:\n",
    "        e = item[0].to(device).long()\n",
    "        r = item[1].to(device).long()\n",
    "        label = item[2].to(device).float()\n",
    "        l1 = item[3].to(device).long()\n",
    "        l2 = item[4].to(device).long()\n",
    "        l3 = item[5].to(device).long()\n",
    "        p = item[6].to(device).long()\n",
    "        el = item[7].to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(e, r, l1, l2, l3, p, el)\n",
    "        loss = criterion(output, torch.sigmoid(label))\n",
    "        valid_loss.append(loss.item())\n",
    "\n",
    "        output = output[:, -1] # (BS, 1)\n",
    "        label = label[:, -1] \n",
    "        pred = (output >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.mean(valid_loss)\n",
    "\n",
    "    return loss, acc, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:02.419508Z",
     "iopub.status.busy": "2021-01-12T01:14:02.418585Z",
     "iopub.status.idle": "2021-01-12T01:14:11.252176Z",
     "shell.execute_reply": "2021-01-12T01:14:11.250847Z"
    },
    "papermill": {
     "duration": 9.448912,
     "end_time": "2021-01-12T01:14:11.252296",
     "exception": false,
     "start_time": "2021-01-12T01:14:01.803384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "train_dataset = SAINTDataset(train_group, NUM_QUESTIONS, max_seq=MAX_SEQ)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=8)\n",
    "\n",
    "valid_dataset = SAINTDataset(valid_group, NUM_QUESTIONS, max_seq=MAX_SEQ, subset='valid')\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BS, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:11.699326Z",
     "iopub.status.busy": "2021-01-12T01:14:11.693131Z",
     "iopub.status.idle": "2021-01-12T01:14:16.276480Z",
     "shell.execute_reply": "2021-01-12T01:14:16.275521Z"
    },
    "papermill": {
     "duration": 5.008395,
     "end_time": "2021-01-12T01:14:16.276589",
     "exception": false,
     "start_time": "2021-01-12T01:14:11.268194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SAINT(dim_model=128,\n",
    "            num_en=2,\n",
    "            num_de=2,\n",
    "            heads_en=4,\n",
    "            heads_de=4,\n",
    "            total_ex=NUM_QUESTIONS, \n",
    "            total_in=2,\n",
    "            seq_len=100\n",
    "            )\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-12T01:14:16.937846Z",
     "iopub.status.busy": "2021-01-12T01:14:16.936298Z",
     "iopub.status.idle": "2021-01-12T04:31:16.413526Z",
     "shell.execute_reply": "2021-01-12T04:31:16.339804Z"
    },
    "papermill": {
     "duration": 11820.122102,
     "end_time": "2021-01-12T04:31:16.413690",
     "exception": false,
     "start_time": "2021-01-12T01:14:16.291588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6507: 100%|██████████| 1152/1152 [06:22<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.653833, train_acc: 0.617966, train_auc: 0.671983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, valid_loss: 0.651383, valid_acc: 0.618819, valid_auc: 0.748260\n",
      "Epoch#1, valid loss 0.6514, Metric loss improved from -inf to 0.7483, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6512: 100%|██████████| 1152/1152 [06:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 0.650869, train_acc: 0.617858, train_auc: 0.766011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, valid_loss: 0.650544, valid_acc: 0.618572, valid_auc: 0.771194\n",
      "Epoch#2, valid loss 0.6505, Metric loss improved from 0.7483 to 0.7712, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6458: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, train_loss: 0.650610, train_acc: 0.617843, train_auc: 0.773138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, valid_loss: 0.650478, valid_acc: 0.618572, valid_auc: 0.773283\n",
      "Epoch#3, valid loss 0.6505, Metric loss improved from 0.7712 to 0.7733, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6514: 100%|██████████| 1152/1152 [06:27<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, train_loss: 0.650538, train_acc: 0.617842, train_auc: 0.775381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, valid_loss: 0.650616, valid_acc: 0.618572, valid_auc: 0.775502\n",
      "Epoch#4, valid loss 0.6506, Metric loss improved from 0.7733 to 0.7755, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6508: 100%|██████████| 1152/1152 [06:23<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, train_loss: 0.650474, train_acc: 0.617842, train_auc: 0.777310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, valid_loss: 0.650332, valid_acc: 0.618572, valid_auc: 0.777450\n",
      "Epoch#5, valid loss 0.6503, Metric loss improved from 0.7755 to 0.7774, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6515: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, train_loss: 0.650410, train_acc: 0.617843, train_auc: 0.779347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, valid_loss: 0.650256, valid_acc: 0.618572, valid_auc: 0.780301\n",
      "Epoch#6, valid loss 0.6503, Metric loss improved from 0.7774 to 0.7803, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6537: 100%|██████████| 1152/1152 [06:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, train_loss: 0.650350, train_acc: 0.617843, train_auc: 0.781085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, valid_loss: 0.650202, valid_acc: 0.618572, valid_auc: 0.781699\n",
      "Epoch#7, valid loss 0.6502, Metric loss improved from 0.7803 to 0.7817, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6512: 100%|██████████| 1152/1152 [06:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, train_loss: 0.650295, train_acc: 0.617847, train_auc: 0.782559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, valid_loss: 0.650162, valid_acc: 0.618600, valid_auc: 0.783768\n",
      "Epoch#8, valid loss 0.6502, Metric loss improved from 0.7817 to 0.7838, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6505: 100%|██████████| 1152/1152 [06:27<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, train_loss: 0.650250, train_acc: 0.617870, train_auc: 0.783840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, valid_loss: 0.650199, valid_acc: 0.618627, valid_auc: 0.784117\n",
      "Epoch#9, valid loss 0.6502, Metric loss improved from 0.7838 to 0.7841, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6509: 100%|██████████| 1152/1152 [06:23<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train_loss: 0.650213, train_acc: 0.617886, train_auc: 0.784853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, valid_loss: 0.650088, valid_acc: 0.618600, valid_auc: 0.784829\n",
      "Epoch#10, valid loss 0.6501, Metric loss improved from 0.7841 to 0.7848, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6502: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, train_loss: 0.650179, train_acc: 0.617914, train_auc: 0.785792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, valid_loss: 0.650058, valid_acc: 0.618655, valid_auc: 0.785818\n",
      "Epoch#11, valid loss 0.6501, Metric loss improved from 0.7848 to 0.7858, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6490: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, train_loss: 0.650143, train_acc: 0.617917, train_auc: 0.787003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, valid_loss: 0.650055, valid_acc: 0.618737, valid_auc: 0.786386\n",
      "Epoch#12, valid loss 0.6501, Metric loss improved from 0.7858 to 0.7864, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6461: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, train_loss: 0.650103, train_acc: 0.617935, train_auc: 0.788054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, valid_loss: 0.650068, valid_acc: 0.618682, valid_auc: 0.788126\n",
      "Epoch#13, valid loss 0.6501, Metric loss improved from 0.7864 to 0.7881, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6506: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, train_loss: 0.650064, train_acc: 0.617966, train_auc: 0.789713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, valid_loss: 0.649931, valid_acc: 0.618682, valid_auc: 0.790307\n",
      "Epoch#14, valid loss 0.6499, Metric loss improved from 0.7881 to 0.7903, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6483: 100%|██████████| 1152/1152 [06:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, train_loss: 0.650020, train_acc: 0.617975, train_auc: 0.791462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, valid_loss: 0.649909, valid_acc: 0.618655, valid_auc: 0.791436\n",
      "Epoch#15, valid loss 0.6499, Metric loss improved from 0.7903 to 0.7914, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6507: 100%|██████████| 1152/1152 [06:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, train_loss: 0.649988, train_acc: 0.617979, train_auc: 0.792574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, valid_loss: 0.649919, valid_acc: 0.618627, valid_auc: 0.792077\n",
      "Epoch#16, valid loss 0.6499, Metric loss improved from 0.7914 to 0.7921, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6507: 100%|██████████| 1152/1152 [06:27<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, train_loss: 0.649963, train_acc: 0.617986, train_auc: 0.793241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, valid_loss: 0.649927, valid_acc: 0.618956, valid_auc: 0.792794\n",
      "Epoch#17, valid loss 0.6499, Metric loss improved from 0.7921 to 0.7928, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6495: 100%|██████████| 1152/1152 [06:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, train_loss: 0.649941, train_acc: 0.618001, train_auc: 0.794060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, valid_loss: 0.649872, valid_acc: 0.618792, valid_auc: 0.793126\n",
      "Epoch#18, valid loss 0.6499, Metric loss improved from 0.7928 to 0.7931, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6491: 100%|██████████| 1152/1152 [06:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, train_loss: 0.649923, train_acc: 0.618017, train_auc: 0.794631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, valid_loss: 0.649834, valid_acc: 0.618792, valid_auc: 0.794109\n",
      "Epoch#19, valid loss 0.6498, Metric loss improved from 0.7931 to 0.7941, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6478: 100%|██████████| 1152/1152 [06:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, train_loss: 0.649906, train_acc: 0.618027, train_auc: 0.795168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, valid_loss: 0.649817, valid_acc: 0.618682, valid_auc: 0.794606\n",
      "Epoch#20, valid loss 0.6498, Metric loss improved from 0.7941 to 0.7946, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6503: 100%|██████████| 1152/1152 [06:27<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, train_loss: 0.649894, train_acc: 0.618048, train_auc: 0.795468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, valid_loss: 0.649867, valid_acc: 0.618655, valid_auc: 0.794548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6459: 100%|██████████| 1152/1152 [06:23<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, train_loss: 0.649878, train_acc: 0.618024, train_auc: 0.795970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, valid_loss: 0.649820, valid_acc: 0.618627, valid_auc: 0.795031\n",
      "Epoch#22, valid loss 0.6498, Metric loss improved from 0.7946 to 0.7950, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6482: 100%|██████████| 1152/1152 [06:27<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, train_loss: 0.649868, train_acc: 0.618066, train_auc: 0.796461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, valid_loss: 0.649803, valid_acc: 0.618819, valid_auc: 0.795249\n",
      "Epoch#23, valid loss 0.6498, Metric loss improved from 0.7950 to 0.7952, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6475: 100%|██████████| 1152/1152 [06:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, train_loss: 0.649856, train_acc: 0.618057, train_auc: 0.796574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, valid_loss: 0.649781, valid_acc: 0.618737, valid_auc: 0.795268\n",
      "Epoch#24, valid loss 0.6498, Metric loss improved from 0.7952 to 0.7953, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6515: 100%|██████████| 1152/1152 [06:24<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, train_loss: 0.649849, train_acc: 0.618092, train_auc: 0.797146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, valid_loss: 0.649765, valid_acc: 0.618874, valid_auc: 0.796104\n",
      "Epoch#25, valid loss 0.6498, Metric loss improved from 0.7953 to 0.7961, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6512: 100%|██████████| 1152/1152 [06:23<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, train_loss: 0.649839, train_acc: 0.618151, train_auc: 0.797234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, valid_loss: 0.649788, valid_acc: 0.618764, valid_auc: 0.795673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6474: 100%|██████████| 1152/1152 [06:24<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, train_loss: 0.649827, train_acc: 0.618137, train_auc: 0.797675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, valid_loss: 0.649788, valid_acc: 0.618847, valid_auc: 0.796373\n",
      "Epoch#27, valid loss 0.6498, Metric loss improved from 0.7961 to 0.7964, saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6501: 100%|██████████| 1152/1152 [06:26<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, train_loss: 0.649819, train_acc: 0.618154, train_auc: 0.797909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, valid_loss: 0.649768, valid_acc: 0.618764, valid_auc: 0.796082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6499: 100%|██████████| 1152/1152 [06:23<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, train_loss: 0.649811, train_acc: 0.618123, train_auc: 0.798239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1152 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, valid_loss: 0.649754, valid_acc: 0.618764, valid_auc: 0.796355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.6492: 100%|██████████| 1152/1152 [06:25<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, train_loss: 0.649803, train_acc: 0.618170, train_auc: 0.798510\n",
      "Epoch 30, valid_loss: 0.649733, valid_acc: 0.618792, valid_auc: 0.796974\n",
      "Epoch#30, valid loss 0.6497, Metric loss improved from 0.7964 to 0.7970, saving model ...\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "epochs = 30\n",
    "history = []\n",
    "auc_max = -np.inf\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_acc, train_auc = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    print(f'Epoch {epoch}, train_loss: {train_loss:5f}, train_acc: {train_acc:5f}, train_auc: {train_auc:5f}')\n",
    "    valid_loss, valid_acc, valid_auc = valid_epoch(model, valid_dataloader, criterion, device)\n",
    "    print(f'Epoch {epoch}, valid_loss: {valid_loss:5f}, valid_acc: {valid_acc:5f}, valid_auc: {valid_auc:5f}')\n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    history.append({\"epoch\":epoch, \"lr\": lr, **{\"train_auc\": train_auc, \"train_acc\": train_acc}, **{\"valid_auc\": valid_auc, \"valid_acc\": valid_acc}})\n",
    "    if valid_auc > auc_max:\n",
    "        print(\"Epoch#%s, valid loss %.4f, Metric loss improved from %.4f to %.4f, saving model ...\" % (epoch, valid_loss, auc_max, valid_auc))\n",
    "        auc_max = valid_auc\n",
    "        torch.save(model.state_dict(), MODEL_BEST)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 26.07899,
     "end_time": "2021-01-12T04:32:08.323188",
     "exception": false,
     "start_time": "2021-01-12T04:31:42.244198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Although I'm happy with how the competition went, I still think I could have improved on my model quite a bit. \n",
    "\n",
    "I had issues using a continuous representation of the prior_question_elapsed_time feature, so in the end I just left the categorical version. The SAINT+ paper found that this feature worked marginally better with a continuous representation, so I would have liked to get that working.\n",
    "\n",
    "I'm also sure that my lag features could have been engineered better. Since several questions were given together in a bundle, they had the same timestamps. So in using a simple lag such as lag = t<sub>n</sub> - t<sub>n-1</sub>, you get a lot of lag=0, which doesn't give much signal to the model. It also feeds the model sequences that can change, depending on how the group was formed. So I would have liked to experiment with this a bit.\n",
    "\n",
    "Finally, there was still a gap between my LB score and my training scores. So I'm sure there were still some issues to resolve on that front.\n",
    "\n",
    "If anyone has any comments or questions, I'd love to hear them. Thanks for looking at my kernel!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 12268.536709,
   "end_time": "2021-01-12T04:32:35.939543",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-12T01:08:07.402834",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
